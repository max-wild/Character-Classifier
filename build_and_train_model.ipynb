{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64 # @param [32, 64, 128]\n",
        "HIDDEN_UNITS = 12 # @param [8, 10, 12, 16]\n",
        "EPOCHS = 3 # @param [3, 4, 5, 7]"
      ],
      "metadata": {
        "id": "X58Aqx7ecUKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlYlrGojh3ay",
        "outputId": "a0dc55a3-c483-47cc-efe9-c0cebf4000cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.0.1+cu118\n",
            "torchvision version: 0.15.2+cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "9DAa0-PZikf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Based agnostic code\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "itLNAuf7hO7U",
        "outputId": "7023ee0a-e577-4fcd-9094-2d4af714ea27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor, Lambda, RandomRotation, RandomAffine\n",
        "\n",
        "# This is using the unbalanced dataset described here:\n",
        "# https://arxiv.org/pdf/1702.05373v1.pdf\n",
        "\n",
        "orient_direction = transforms.Compose([\n",
        "    ToTensor(),\n",
        "    RandomRotation((90, 90)),  # Rotate 90 degrees\n",
        "    Lambda(lambda x: torch.flip(x, (0, 1))),  # Flip horizontally\n",
        "    RandomAffine(  # Apply random transformations to make the dataset more robust\n",
        "        degrees=25,\n",
        "        translate=(0.45, 0.45),\n",
        "        scale=(0.6, 1),\n",
        "        shear=(-30, 30, -30, 30)\n",
        "    )\n",
        "])\n",
        "\n",
        "train_data = datasets.EMNIST(\n",
        "    root='data',\n",
        "    split='byclass',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=orient_direction  # Ensure we receive a tensor\n",
        ")\n",
        "\n",
        "test_data = datasets.EMNIST(\n",
        "    root='data',\n",
        "    split='byclass',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=orient_direction\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGUocIhkiFZp",
        "outputId": "222fd8c6-8c8e-4749-a0e6-87092d332632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to data/EMNIST/raw/gzip.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 561753746/561753746 [00:05<00:00, 93723128.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/EMNIST/raw/gzip.zip to data/EMNIST/raw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "print(f'{class_names=}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR0HbF3aj44p",
        "outputId": "75d49409-6d38-483e-c9ae-6c1fa445af52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class_names=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Plot 10 images\n",
        "fig = plt.figure(figsize=(10, 4))\n",
        "rows, cols = 2, 5\n",
        "for i in range(1, rows * cols + 1):\n",
        "\n",
        "    random_idx = torch.randint(0, len(train_data), size=[1]).item()  # Use item() to get the scalar\n",
        "    img, label = train_data[random_idx]\n",
        "\n",
        "    fig.add_subplot(rows, cols, i)\n",
        "    plt.imshow(img.squeeze(), cmap='gray')\n",
        "    plt.title(class_names[label])\n",
        "    plt.axis(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "PmWNRDSAkMWG",
        "outputId": "eaf5c2c2-4f5c-4a13-d87c-4d85cb499acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Define dataloaders\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "test_dataloader = DataLoader(test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False)\n",
        "\n",
        "print(f'Train DataLoader: {train_dataloader}\\nTest DataLoader: {test_dataloader}\\n')\n",
        "print(f'Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}')\n",
        "print(f'Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lnLOX5omwNz",
        "outputId": "e874edb4-2794-4de1-f820-11e2f9cd7abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataLoader: <torch.utils.data.dataloader.DataLoader object at 0x7b2a83526dd0>\n",
            "Test DataLoader: <torch.utils.data.dataloader.DataLoader object at 0x7b2a83526f20>\n",
            "\n",
            "Length of train dataloader: 10906 batches of 64\n",
            "Length of test dataloader: 1818 batches of 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A look inside the DataLoader-- (features format should be NCHW)\n",
        "example_batch_features, example_batch_labels = next(iter(train_dataloader))\n",
        "print(f'Features shape: {example_batch_features.shape}\\nLabels shape: {example_batch_labels.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwo8Juajdgux",
        "outputId": "40160608-33c8-4aec-f011-0b51a97b0bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: torch.Size([64, 1, 28, 28])\n",
            "Labels shape: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Define our model\n",
        "# Using the TinyVGG CNN architecture from https://poloclub.github.io/cnn-explainer/\n",
        "from torch import nn\n",
        "\n",
        "class CharacterClassifer(nn.Module):\n",
        "    def __init__(self, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1,  # 1 channel--black and white\n",
        "                      out_channels=HIDDEN_UNITS,\n",
        "                      kernel_size=3,  # Dimensions of inspecting square\n",
        "                      stride=1,  # Default\n",
        "                      padding=1),\n",
        "            nn.ReLU(),  # Nonlinearity baby ðŸ˜‹\n",
        "            nn.Conv2d(HIDDEN_UNITS, HIDDEN_UNITS, 3, padding=1),  # There're many channels of hidden units now\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2)  # Default stride is the same as kernel\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(HIDDEN_UNITS, HIDDEN_UNITS, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(HIDDEN_UNITS, HIDDEN_UNITS, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(HIDDEN_UNITS * 7 * 7, output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ODABD12QeLYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Make our model\n",
        "model_0 = CharacterClassifer(output_shape=len(class_names)).to(device)\n",
        "model_0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzEACL_Bh8bp",
        "outputId": "716d2930-f704-42ff-914f-4d82a6c0f9d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharacterClassifer(\n",
              "  (block_1): Sequential(\n",
              "    (0): Conv2d(1, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block_2): Sequential(\n",
              "    (0): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=588, out_features=62, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Define optimizer, loss function, and accuracy function\n",
        "import torchmetrics\n",
        "\n",
        "accuracy_fn = torchmetrics.Accuracy(task='multiclass', num_classes=len(class_names)).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                            lr=0.1)"
      ],
      "metadata": {
        "id": "Vs_O4Uaud7bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Evaluation function\n",
        "\n",
        "def evaluate_model(model: torch.nn.Module,\n",
        "                   data_loader: torch.utils.data.DataLoader,\n",
        "                   loss_fn: torch.nn.Module,\n",
        "                   accuracy_fn: torchmetrics.metric.Metric,\n",
        "                   device: torch.device):\n",
        "\n",
        "    loss, acc = 0, 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in data_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_pred = model(X)\n",
        "            loss += loss_fn(y_pred, y)\n",
        "            acc += accuracy_fn(y_pred.argmax(dim=1), y)\n",
        "\n",
        "        loss /= len(data_loader)\n",
        "        acc /= len(data_loader)\n",
        "\n",
        "    return {'model_name': model.__class__.__name__,\n",
        "            'model_loss': loss.item(),\n",
        "            'model_acc': acc}"
      ],
      "metadata": {
        "id": "FB-1AEbqeGqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Training and Testing Steps\n",
        "\n",
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn: torchmetrics.metric.Metric,\n",
        "               device: torch.device):\n",
        "    train_loss, train_acc = 0, 0\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for batch, (X, y) in enumerate(data_loader):\n",
        "        # Send data to GPU\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_preds = model(X)\n",
        "\n",
        "        # 2. Calculate loss\n",
        "        loss = loss_fn(y_preds, y)\n",
        "        train_loss += loss\n",
        "\n",
        "        batch_acc = accuracy_fn(y_preds.argmax(dim=1), y)\n",
        "        train_acc += batch_acc\n",
        "\n",
        "        # 3. Zero the optimizer gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Backpropagate\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. SGD step\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate loss and accuracy per epoch\n",
        "    train_loss /= len(data_loader)\n",
        "    train_acc /= len(data_loader)\n",
        "    print(f'Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%')\n",
        "\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn: torchmetrics.metric.Metric,\n",
        "              device: torch.device):\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for X, y in data_loader:\n",
        "\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred = model(X)\n",
        "\n",
        "            # 2. Calculate loss and accuracy\n",
        "            test_loss += loss_fn(test_pred, y)\n",
        "            test_acc += accuracy_fn(torch.argmax(test_pred, dim=1), y)\n",
        "\n",
        "        # Adjust metrics and print out\n",
        "        test_loss /= len(data_loader)\n",
        "        test_acc /= len(data_loader)\n",
        "        print(f'Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n')"
      ],
      "metadata": {
        "id": "uHxO5bAnkt7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Training time function\n",
        "import math\n",
        "\n",
        "def print_train_time(start: float, end: float, device: torch.device):\n",
        "    total_time = end - start\n",
        "    minutes = math.floor(total_time / 60)\n",
        "    seconds = total_time % 60\n",
        "    print(f'Train time on {device}: {minutes} minutes and {seconds:.2f} seconds')"
      ],
      "metadata": {
        "id": "R0bYYqjLm0Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Train the model\n",
        "from tqdm.auto import tqdm\n",
        "from timeit import default_timer\n",
        "\n",
        "begin_time = default_timer()\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    print(f'Epoch: {epoch}\\n---------------------------------')\n",
        "\n",
        "    # Train step\n",
        "    train_step(model=model_0,\n",
        "              data_loader=train_dataloader,\n",
        "              loss_fn=loss_fn,\n",
        "              optimizer=optimizer,\n",
        "              accuracy_fn=accuracy_fn,\n",
        "              device=device\n",
        "    )\n",
        "\n",
        "    # Test step\n",
        "    if epoch % 2 == 0 or epoch == EPOCHS - 1:\n",
        "        test_step(model=model_0,\n",
        "                  data_loader=test_dataloader,\n",
        "                  loss_fn=loss_fn,\n",
        "                  accuracy_fn=accuracy_fn,\n",
        "                  device=device\n",
        "        )\n",
        "\n",
        "    print('')  # Newline\n",
        "\n",
        "end_time = default_timer()\n",
        "print_train_time(begin_time, end_time, device)"
      ],
      "metadata": {
        "id": "1r1tbPlslZhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Create models directory (if it doesn't already exist), see: https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir\n",
        "MODEL_PATH = Path('models')\n",
        "MODEL_PATH.mkdir(parents=True, # create parent directories if needed\n",
        "                 exist_ok=True # if models directory already exists, don't error\n",
        ")\n",
        "\n",
        "STATE_DICT_NAME = 'character_classifier_state_dict.pth'\n",
        "STATE_DICT_SAVE_PATH = MODEL_PATH / STATE_DICT_NAME\n",
        "\n",
        "print(f'Saving state dict to: {STATE_DICT_SAVE_PATH}')\n",
        "torch.save(obj=model_0.state_dict(),\n",
        "           f=STATE_DICT_SAVE_PATH)"
      ],
      "metadata": {
        "id": "QI7qb-2qm_DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'character_classifier.pth'\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "print(f'Saving model to: {MODEL_SAVE_PATH}')\n",
        "torch.save(obj=model_0,\n",
        "           f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "6L6nIyFUDcRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Test that the model works\n",
        "\n",
        "random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "test_img, test_label = train_data[random_idx]\n",
        "\n",
        "plt.imshow(test_img.squeeze(), cmap='gray')\n",
        "plt.title(class_names[test_label])\n",
        "test_img.shape"
      ],
      "metadata": {
        "id": "nS0Vj3-DBVr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.to(device)\n",
        "test_img.to(device)\n",
        "\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "\n",
        "    pred_logit = model_0(test_img.unsqueeze(dim=0))\n",
        "    pred_probs = torch.softmax(pred_logit.squeeze(), dim=0) # .squeeze(), dim=0)\n",
        "    pred_class = pred_probs.argmax(dim=0)\n",
        "\n",
        "print(f'The model guesses that the input is a: {class_names[pred_class]}')"
      ],
      "metadata": {
        "id": "ReQAI2RiCVyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Now convert to onnx format for use in browsers\n",
        "!pip install onnx"
      ],
      "metadata": {
        "id": "6ub-qrAaF_cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to onnx\n",
        "model_0.to('cpu')\n",
        "dummy_input = torch.zeros(1, 1, 28, 28).to('cpu')\n",
        "\n",
        "model_0.eval()\n",
        "torch.onnx.export(model_0,\n",
        "                  dummy_input,\n",
        "                  'torchmodel_EMINST.onnx',\n",
        "                  verbose=True,\n",
        "                  opset_version=9)  # VERY IMPORTANT -- only works in v7-9"
      ],
      "metadata": {
        "id": "TfS8zJ7YDA-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Now, need to make a model that's set up to work in browser\n",
        "\n",
        "class CharClassiferWeb(nn.Module):\n",
        "    def __init__(self, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1,  # 1 channel--black and white\n",
        "                      out_channels=HIDDEN_UNITS,\n",
        "                      kernel_size=3,  # Dimensions of inspecting square\n",
        "                      stride=1,  # Default\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(HIDDEN_UNITS, HIDDEN_UNITS, 3, padding=1),  # There're many channels of hidden units now\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2)  # Default stride is the same as kernel\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(HIDDEN_UNITS, HIDDEN_UNITS, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(HIDDEN_UNITS, HIDDEN_UNITS, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(HIDDEN_UNITS * 7 * 7, output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "\n",
        "        # Pre-process inputs\n",
        "        x = x.reshape(280, 280, 4)\n",
        "        x = torch.narrow(x, dim=2, start=3, length=1)  # Get the alpha color value\n",
        "        x = x.reshape(1, 1, 280, 280)  # Put into NCHW format\n",
        "        x = nn.functional.avg_pool2d(x, 10, stride=10)  # Lower resolution from 280x280 to 28x28\n",
        "        x = x / 255  # Alpha value is 0-255, accomdate for that\n",
        "\n",
        "        # Inference\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        # Post-process logits -> probabilites\n",
        "        x = torch.softmax(x, dim=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "4T1WIS-cHUMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_web = CharClassiferWeb(output_shape=len(class_names)).to('cpu')"
      ],
      "metadata": {
        "id": "MQf5iJazwO4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_web.load_state_dict(model_0.state_dict())"
      ],
      "metadata": {
        "id": "CBhldGJIwtxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, output to ONNX\n",
        "model_web.to('cpu')\n",
        "dummy_input = torch.zeros(280 * 280 * 4).to('cpu')\n",
        "\n",
        "model_web.eval()\n",
        "torch.onnx.export(model_web,\n",
        "                  dummy_input,\n",
        "                  'torchmodel_Web.onnx',\n",
        "                  verbose=True,\n",
        "                  opset_version=9)   # VERY IMPORTANT -- only works in v7-9"
      ],
      "metadata": {
        "id": "OYdAFPHtwvmv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}